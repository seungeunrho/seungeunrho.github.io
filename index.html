<!DOCTYPE html>
<html lang="en">

<head>
  <link rel="icon" href="assets/icons/icon.png">
  <!-- Basic Page Needs
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta charset="utf-8">
  <title>Seungeun Rho</title>
  <meta name="description" content="">
  <meta name="author" content="">

  <!-- Mobile Specific Metas
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- FONT
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link href="https://fonts.googleapis.com/css?family=Raleway:400,300,600" rel="stylesheet" type="text/css">

  <!-- CSS
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="stylesheet" href="css/normalize.css">
  <link rel="stylesheet" href="css/skeleton.css">
  <link rel="stylesheet" href="css/custom.css">

  <!-- Favicon
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <!-- <link rel="icon" type="image/png" href="assets/"> -->

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-1J19VDQYCK"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'G-1J19VDQYCK');
  </script>
  <!-- Video playback speed and no controls -->
  <script defer src="js/video.js"></script>
</head>

<body>
  <div class="container">
    <!-- NAVBAR --------------------------------- -->
    <!-- <div class="navbar-spacer"></div>
    <nav class="navbar">
      <div class="container">
        <ul class="navbar-list">
          <li class="navbar-item"><a class="navbar-link" href="index.html">About</a></li>
          <li class="navbar-item"><a class="navbar-link" href="/blog.html">Blog</a></li>
        </ul>
      </div>
    </nav> -->

    <!-- Personal Info  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
    <div class="row profile-row" style="margin-top: 4%">
      <div class="one columns"></div>
      <div class="three columns">
        <!-- Profile photo  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
        <div style="text-align: center;">
          <img src="assets/img/photo.jpg" class="profile-photo" alt="profile photo"><br>
        </div>
        <!-- Name
        –––––––––––––––––––––––––––––––––––––––––––––––––– -->
        <h5 style="text-align: center;">Seungeun Rho</h5>
        <!-- Social links
        –––––––––––––––––––––––––––––––––––––––––––––––––– -->
        <div id="social">
          <a href="https://github.com/seungeunrho"><img src="assets/icons/github.png" class="iico" /></a>
          <a href="assets/pdfs/CV.pdf"><img src="assets/icons/file.png" class="iico" /></a>
          <img src="assets/icons/mail.png" style="cursor: pointer;" class="iico" id="iemail" title="click to reveal" />
        </div>
        <div id="demail"></div> <!-- will reveal email -->
      </div>

      <div class="eight columns" style="margin-top: 5%;">
        <p style="text-align:justify;">
          <!-- Self-introduction
          –––––––––––––––––––––––––––––––––––––––––––––––––– -->
          I'm a first-year Robotics Ph.D. student at Georgia Tech, advised by
          <a href="https://www.cc.gatech.edu/~sha9/" style="text-decoration: none;">Dr. Sehoon Ha</a>. I am interested in reinforcement learning and its applications on robotics.

        </p>
        <!-- <strong>Competences:</strong>
        <a>python</a>,
        <a>pytorch</a>,
        <a>pybullet</a>,
        <a>iGibson</a>,
        <a>OpenCV</a>,
        <a>numpy</a>,
        <a>Tensorflow</a>,
        <a>C/C++</a>,
        <a>ROS</a>,
        <a>docker</a> -->

<!--        <h5><u>News</u></h5>-->
<!--        <ul>-->
<!--          <li> <b>JUL'23</b> - Our work on Learning-oriented Robot Design was accepted at IROS 2023 <a-->
<!--            href="https://learning-robot.github.io/">[project page]</a></li>-->
<!--          <li> <b>MAR'23</b> - Check out our latest work on Design a Learning Robot <a-->
<!--              href="https://learning-robot.github.io/">[project page]</a></li>-->
<!--          <li> <b>APR'22</b> - Human Motion Control of Quadrupedal Robots accepted at RSS <a-->
<!--              href="https://sites.google.com/view/humanconquad/">[project page]</a></li>-->
<!--          <li> <b>SEP'21</b> - Excited to be joining <a href="https://x.company">X - the moonshot factory</a> ( <a-->
<!--              href="https://everydayrobots.com">Everyday Robots</a> ) for PhD-->
<!--            Residency!</li>-->
<!--          <li> <b>SEP'21</b> - Check out our work on Learning Sidewalk Navigation <a-->
<!--              href="./navigation.html">[project page]</a></li>-->
<!--          &lt;!&ndash; <li> <b>MAY'21</b> - Awarded the fellowship by the Machine Learning Center at Georgia Tech. <a href="https://mlatgt.blog/2021/05/10/the-machine-learning-center-awards-inaugural-mlgt-fellows/">[link]</a> </li> &ndash;&gt;-->
<!--          &lt;!&ndash; <li> <b>FEB'21</b> Paper on Learning Human Search Behavior accepted at EUROGRAPHICS'2021! <a href="https://arxiv.org/pdf/2011.03618.pdf">[pdf]</a><a href="https://arxiv.org/abs/2011.03618">[arXiv]</a></li> &ndash;&gt;-->
<!--          &lt;!&ndash; <li> <b>DEC'20</b> Paper on Few-shot visual sensor meta-adaptation accepted at ICRA'2021! <a href="https://arxiv.org/pdf/2011.03609.pdf">[pdf]</a><a href="http://arxiv.org/abs/2011.03609">[arXiv]</a></li> &ndash;&gt;-->
<!--        </ul>-->


      </div>

    </div>
  </div>

  <!-- Companies
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
<!--  <div class="container">-->
<!--    <div class="div_line"></div><br>-->
<!--    <div class="row">-->
<!--      <div class="one column hide-on-small">&nbsp;</div>-->
<!--      <div class="five columns center">-->
<!--        <a href="https://www.gatech.edu/">-->
<!--          <img src="assets/icons/org/GeorgiaTechLogo.png" alt="Georgia Tech Logo" class="logo">-->
<!--        </a>-->
<!--        <p>-->
<!--          PhD in Computer Science<br>2023 - -->
<!--        </p>-->
<!--      </div>-->
<!--&lt;!&ndash;      <div class="five columns center">&ndash;&gt;-->
<!--&lt;!&ndash;        <div class="row">&ndash;&gt;-->
<!--&lt;!&ndash;          <a href="https://everydayrobots.com">&ndash;&gt;-->
<!--&lt;!&ndash;            <img src="assets/icons/org/EverydayRobotsLogo.gif" alt="Everyday Robots Logo" class="logo">&ndash;&gt;-->
<!--&lt;!&ndash;          </a>&ndash;&gt;-->
<!--&lt;!&ndash;          <a href="https://x.company">&ndash;&gt;-->
<!--&lt;!&ndash;            <img src="assets/icons/org/X the moonshot factory logo.png" alt="Google X Logo" class="logo">&ndash;&gt;-->
<!--&lt;!&ndash;          </a>&ndash;&gt;-->
<!--&lt;!&ndash;        </div>&ndash;&gt;-->
<!--&lt;!&ndash;        <p>&ndash;&gt;-->
<!--&lt;!&ndash;          AI Residency<br>2021 - 2022&ndash;&gt;-->
<!--&lt;!&ndash;        </p>&ndash;&gt;-->
<!--&lt;!&ndash;      </div>&ndash;&gt;-->
<!--    </div>-->
<!--  </div>-->
  

  <!-- Publications
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <div class="container">
    <br>
    <div class="div_line"></div><br>
    <h5><u>Publications</u></h5>

    <!-- PUBLICATION ENTRY –––––––––––––––––––––––––––––––––––––––––––––––––– -->
   

    <!-- PUBLICATION ENTRY –––––––––––––––––––––––––––––––––––––––––––––––––– -->
    <div class="row video-row">
      <!-- MEDIA SECTION –––––––––––––––––––––––––––––––––––––––––––––––––– -->
      <div class="four columns">
        <div class="video-container">
          <video class="no-controls-video" autoplay loop muted preload="auto" playsinline>
            <source src="assets/videos/behavior_representations.mp4" type="video/mp4">
          </video>
        </div>
      </div>
      <div class="eight columns text-column">
        <!-- TITLE –––––––––––––––––––––––––––––––––––––––––––––––––– -->
        <div class="project_title">Relax, it doesn't matter how you get there!</div>
        <!-- AUTHORS + VENUE –––––––––––––––––––––––––––––––––––––––––––––––––– -->
        <br><em>Mehdi Azabou, Michael Mendelson, <strong>Maks Sorokin</strong>, Shantanu Thakoor, Nauman Ahad, Carolina
          Urzay, Eva L Dyer</em>
        <br><em><span class="venue">Neural Information Processing Systems (NeurIPS) 2023 - Spotlight</span></em>
        <!-- DESCRIPTION –––––––––––––––––––––––––––––––––––––––––––––––––– -->
        <p class="project_info">
          We introduce Bootstrap Across Multiple Scales (BAMS), a multi-scale self-supervised representation learning
          model for
          behavior analysis. We combine a pooling module that aggregates features extracted over encoders with different
          temporal
          receptive fields, and design latent objectives to bootstrap the representations in each respective
          space to encourage disentanglement across different timescales.
        </p>

        <!-- LINKS –––––––––––––––––––––––––––––––––––––––––––––––––– -->
        <a href="https://multiscale-behavior.github.io/">[project page]</a>
        <a href="https://arxiv.org/pdf/2303.08811.pdf">[pdf]</a>
        <a href="https://arxiv.org/abs/2303.08811">[arXiv]</a>
      </div>
    </div>

    <!-- PUBLICATION ENTRY –––––––––––––––––––––––––––––––––––––––––––––––––– -->
    <div class="row video-row">
      <!-- MEDIA SECTION –––––––––––––––––––––––––––––––––––––––––––––––––– -->
      <div class="four columns">
        <div class="video-container">
          <video class="no-controls-video" autoplay loop muted preload="auto" playsinline>
            <source src="assets/videos/urban_navigation.mp4" type="video/mp4">
          </video>
        </div>
      </div>
      <div class="eight columns text-column">
        <!-- TITLE –––––––––––––––––––––––––––––––––––––––––––––––––– -->
        <div class="project_title">Learning to Navigate Sidewalks in Outdoor Environments</div>
        <!-- AUTHORS + VENUE –––––––––––––––––––––––––––––––––––––––––––––––––– -->
        <br><em><strong>Maks Sorokin</strong>, Jie Tan, C. Karen Liu, Sehoon Ha</em>
        <br><em><span class="venue">IEEE Robotics and Automation Letters (RA-L) 2022</span></em>
        <!-- DESCRIPTION –––––––––––––––––––––––––––––––––––––––––––––––––– -->
        <p class="project_info">
          We design a system which enables zero-shot vision-based policy transfer to the real-world outdoor environments
          for sidewalk navigation task.
          Our approach is evaluated on a quadrupedal robot navigating sidewalks in the real world walking 3.2 kilometers
          with a limited number of human interventions.
        </p>

        <!-- LINKS –––––––––––––––––––––––––––––––––––––––––––––––––– -->
        <a href="./navigation.html">[project page]</a>
        <a href="https://arxiv.org/pdf/2109.05603.pdf">[pdf]</a>
        <a href="https://arxiv.org/abs/2109.05603">[arXiv]</a>
        <a href="https://www.youtube.com/watch?v=JsAZy3YETwQ">[video]</a>
        <a href="https://techxplore.com/news/2021-09-robot-efficiently-sidewalks-urban-environments.html">[TechXplore
          article]</a>
      </div>
    </div>

    <!-- PUBLICATION ENTRY –––––––––––––––––––––––––––––––––––––––––––––––––– -->
    <div class="row video-row">
      <!-- MEDIA SECTION –––––––––––––––––––––––––––––––––––––––––––––––––– -->
      <div class="four columns">
        <div class="video-container">
          <video class="no-controls-video" autoplay loop muted preload="auto" playsinline>
            <source src="assets/videos/object_search_animation.mp4" type="video/mp4">
          </video>
        </div>
      </div>
      <div class="eight columns text-column">
        <!-- TITLE –––––––––––––––––––––––––––––––––––––––––––––––––– -->
        <div class="project_title">Learning Human Search Behavior from Egocentric View</div>
        <!-- AUTHORS + VENUE –––––––––––––––––––––––––––––––––––––––––––––––––– -->
        <br><em><strong>Maks Sorokin</strong>, Wenhao Yu, Sehoon Ha, C. Karen Liu </em>
        <br><em><span class="venue">EUROGRAPHICS 2021</span></em>
        <!-- DESCRIPTION –––––––––––––––––––––––––––––––––––––––––––––––––– -->
        <p class="project_info">
          We train vision-based agent to perform object searching in photorealistic 3D scene.
          And propose a motion synthesis mechanism for head motion re-targeting.
          Using which we enable object searching behaviour with animated human character (PFNN/NSM).
        </p>

        <!-- LINKS –––––––––––––––––––––––––––––––––––––––––––––––––– -->
        <a href="https://arxiv.org/pdf/2011.03618.pdf">[pdf]</a>
        <a href="https://arxiv.org/abs/2011.03618">[arXiv]</a>
        <a href="https://www.youtube.com/watch?v=LvSHpmjt8pU">[video]</a>
        <a href="https://www.youtube.com/watch?v=NzsCT3a7rpY">[talk(20 min)]</a>
      </div>
    </div>


    <!-- PUBLICATION ENTRY –––––––––––––––––––––––––––––––––––––––––––––––––– -->
    <div class="row video-row">
      <!-- MEDIA SECTION –––––––––––––––––––––––––––––––––––––––––––––––––– -->
      <div class="four columns">
        <div class="video-container">
          <video class="no-controls-video" autoplay loop muted preload="auto" playsinline>
            <source src="assets/videos/sensor_height_adaptation.mp4" type="video/mp4">
          </video>
        </div>
      </div>
      <div class="eight columns text-column">
        <!-- TITLE –––––––––––––––––––––––––––––––––––––––––––––––––– -->
        <div class="project_title">A Few Shot Adaptation of Visual Navigation Skills to New Observations using
          Meta-Learning</div>
        <!-- AUTHORS + VENUE –––––––––––––––––––––––––––––––––––––––––––––––––– -->
        <br><em>Qian Luo, <strong>Maks Sorokin</strong>, Sehoon Ha</em>
        <br><em><span class="venue">The IEEE International Conference on Robotics and Automation (ICRA) 2021</span></em>
        <!-- DESCRIPTION –––––––––––––––––––––––––––––––––––––––––––––––––– -->
        <p class="project_info">
          We show how vision-based navigation agents can be trained to adapt to new sensor configurations with only
          three shots of experience.
          Rapid adaptation is achieved by introducing a bottleneck between perception and control networks, and through
          the perception component's meta-adaptation.
        </p>
        <!-- LINKS –––––––––––––––––––––––––––––––––––––––––––––––––– -->
        <a href="https://arxiv.org/pdf/2011.03609.pdf">[pdf]</a>
        <a href="http://arxiv.org/abs/2011.03609">[arXiv]</a>
      </div>
    </div>

  </div>

  <!-- Projects
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <div class="container">
    <br>
    <div class="div_line"></div><br>
    <h5><u>Projects</u></h5>

    <!-- PROJECT ENTRY ###
    –––––––––––––––––––––––––––––––––––––––––––––––––– -->
    <div class="row video-row">
      <!-- MEDIA SECTION
      –––––––––––––––––––––––––––––––––––––––––––––––––– -->
      <div class="four columns">
        <div class="video-container">
          <img src="assets/img/sim2sim.png">
        </div>
      </div>
      <div class="eight columns">
        <!-- TITLE
        –––––––––––––––––––––––––––––––––––––––––––––––––– -->
        <div class="project_title">Real2Sim Image adaptation</div>
        <br><em><span class="venue">2019</span></em>
        <!-- DESCRIPTION
        –––––––––––––––––––––––––––––––––––––––––––––––––– -->
        <p class="project_info">
          Image domain adaptation through the conversion of images with randomized textures (or real images) to a
          canonical image representation.
          Replication of a <a href="https://arxiv.org/abs/1812.07252">RCAN paper</a> with different loss modeling (<a
            href="https://arxiv.org/abs/1603.08155">Perceptual/Feature Loss</a> instead of GAN loss).
        </p>
        <!-- LINKS
        –––––––––––––––––––––––––––––––––––––––––––––––––– -->
        <a href="https://github.com/initmaks/ran2can">[github]</a>

      </div>
    </div>



    <!-- PUBLICATION ENTRY –––––––––––––––––––––––––––––––––––––––––––––––––– -->
    <div class="row video-row">
      <!-- MEDIA SECTION –––––––––––––––––––––––––––––––––––––––––––––––––– -->
      <div class="four columns">
        <div class="video-container">
          <video id="car_bc" class="no-controls-video" autoplay loop muted preload="auto" playsinline>
            <source src="assets/videos/drive.mp4" type="video/mp4">
          </video>
        </div>
      </div>
      <div class="eight columns text-column">
        <!-- TITLE –––––––––––––––––––––––––––––––––––––––––––––––––– -->
        <div class="project_title">Behavioral Clonning for Autonomous Driving</div>
        <br><em><span class="venue">2017</span></em>
        <!-- DESCRIPTION –––––––––––––––––––––––––––––––––––––––––––––––––– -->
        <p class="project_info">
          End-to-end (image-to-steering wheel) control policy learning from data collected over multiple laps with
          off-the-track recoveries generated by human.
        </p>

        <!-- LINKS –––––––––––––––––––––––––––––––––––––––––––––––––– -->
        <a href="https://github.com/initmaks/Self-driving_car_ND/tree/master/Behavioral-Cloning">[github]</a>
      </div>
    </div>

  </div>

  <br>
  <br>

  <!-- Teaching –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <div class="container">
    <div class="div_line"></div><br><br>
    <div class="row profile-row">
      <div class="one columns hide-on-small">&nbsp;</div>
      <div class="nine columns ">

        <h5><u>Teaching Experience</u></h5>
        <br>CS4496 - Computer Animation class by
        <a href="https://www.cc.gatech.edu/people/thomas-ploetz"> Dr. Sehoon Ha</a>
        <br><br>
        <ul>
          <li><strong>SPRING 2023</strong>: Teaching Assistant </li>
        </ul>
        <br>
<!--        <h5><u>Scholarly Activities</u></h5>-->
<!--        <ul>-->
<!--          <li><strong>IROS 2023</strong> - Session co-chair Mechanism Design </li>-->
<!--          <li><strong>RA-L 2023</strong> - Reviewer at IEEE Robotics and Automation Letters </li>-->
<!--          <li><strong>RSS 2023</strong> - Reviewer at Proceedings of Robotics: Science and Systems </li>-->
<!--          <li><strong>RA-L 2022</strong> - Reviewer at IEEE Robotics and Automation Letters</li>-->
<!--          <li><strong>ICRA 2021</strong> - Reviewer at IEEE International Conference on Robotics and Automation</li>-->
<!--        </ul>-->
      </div>
    </div>
  </div>


  <!-- End Document
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <!-- attempt hiding from spambots :p - snippet credits Andrej Karpathy - karpathy.ai source code -->
  <script type="text/javascript">
    var e_is_shown = false;
    document.getElementById('iemail').addEventListener("click", function () {
      let demail = document.getElementById('demail');
      demail.innerHTML = 'm' + 'aks' + ' _a' + 't_ ' + 'gatech' + '.' + 'e' + 'du';
      demail.style.opacity = e_is_shown ? 0 : 1;
      e_is_shown = !e_is_shown;
    })
  </script>


  <!-- ### FOOTER ### -->

<!--  <br>-->
<!--  <br>-->

<!--  <br>-->
<!--  <br>-->
<!--  <div class="div_line"></div><br>-->

<!--  <p style="color:gray; text-align:center; font-size: small;">-->
<!--    <h7 style="text-decoration: none;">consider checking out: </h7><br><br>-->
<!--    <a href="https://www.givewell.org/"><img src="assets/icons/gw.jpg" style="width:100px;"></a>-->
<!--    <a href="https://www.givingwhatwecan.org/"><img src="assets/icons/gwwc.png" style="width:100px;"></a>-->
<!--    <a href="https://www.effectivealtruism.org/"><img src="assets/icons/ea.png" style="width:80px; margin:10px"></a>-->

<!--  </p>-->


<!--  <div class="div_line"></div><br>-->

<!--  <p style="color:gray; text-align:center; font-size: small;">-->
<!--    2023© Seungeun Rho<br>-->
<!--    built using <a href="http://getskeleton.com/">Skeleton</a>,-->
<!--    icon credits <a href="https://www.flaticon.com/"> flaticon</a>,-->
<!--    hosted by <a href="https://pages.github.com/"> GitHub Pages</a>❤️-->
<!--    <br>-->
<!--    <br>-->
<!--    feel free to copy: <a href="https://github.com/initmaks/initmaks.github.io">this page</a>-->
<!--  </p>-->

</body>

</html>
<!DOCTYPE html>
<html lang="en">

<head>
  <link rel="icon" href="assets/icons/icon.png">
  <!-- Basic Page Needs
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta charset="utf-8">
  <title>Seungeun Rho</title>
  <meta name="description" content="">
  <meta name="author" content="">

  <!-- Mobile Specific Metas
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- FONT
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link href="https://fonts.googleapis.com/css?family=Raleway:400,300,600" rel="stylesheet" type="text/css">

  <!-- CSS
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="stylesheet" href="css/normalize.css">
  <link rel="stylesheet" href="css/skeleton.css">
  <link rel="stylesheet" href="css/custom.css">

  <!-- Favicon
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <!-- <link rel="icon" type="image/png" href="assets/"> -->

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-1J19VDQYCK"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'G-1J19VDQYCK');
  </script>
  <!-- Video playback speed and no controls -->
  <script defer src="js/video.js"></script>
</head>

<body>
  <div class="container">
    <!-- NAVBAR --------------------------------- -->
    <!-- <div class="navbar-spacer"></div>
    <nav class="navbar">
      <div class="container">
        <ul class="navbar-list">
          <li class="navbar-item"><a class="navbar-link" href="index.html">About</a></li>
          <li class="navbar-item"><a class="navbar-link" href="/blog.html">Blog</a></li>
        </ul>
      </div>
    </nav> -->

    <!-- Personal Info  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
    <div class="row profile-row" style="margin-top: 4%">
      <div class="one columns"></div>
      <div class="three columns">
        <!-- Profile photo  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
        <div style="text-align: center;">
          <img src="assets/img/photo.jpg" class="profile-photo" alt="profile photo"><br>
        </div>
        <!-- Name
        –––––––––––––––––––––––––––––––––––––––––––––––––– -->
        <h5 style="text-align: center;">Seungeun Rho</h5>
        <!-- Social links
        –––––––––––––––––––––––––––––––––––––––––––––––––– -->
        <div id="social">
          <a href="https://github.com/seungeunrho"><img src="assets/icons/github.png" class="iico" /></a>
          <a href="assets/pdfs/SeungeunRho_CV.pdf"><img src="assets/icons/file.png" class="iico" /></a>
          <img src="assets/icons/mail.png" style="cursor: pointer;" class="iico" id="iemail" title="click to reveal" />
        </div>
        <div id="demail"></div> <!-- will reveal email -->
      </div>

      <div class="eight columns" style="margin-top: 5%;">
        <p style="text-align:justify;">
          <!-- Self-introduction
          –––––––––––––––––––––––––––––––––––––––––––––––––– -->
          Hi, I'm a first-year Computer Science Ph.D. student at Georgia Tech, advised by
          <a href="https://www.cc.gatech.edu/~sha9/" style="text-decoration: none;">Dr. Sehoon Ha</a>. I am interested in reinforcement learning and its applications on robotics.

        </p>
        <!-- <strong>Competences:</strong>
        <a>python</a>,
        <a>pytorch</a>,
        <a>pybullet</a>,
        <a>iGibson</a>,
        <a>OpenCV</a>,
        <a>numpy</a>,
        <a>Tensorflow</a>,
        <a>C/C++</a>,
        <a>ROS</a>,
        <a>docker</a> -->

<!--        <h5><u>News</u></h5>-->
<!--        <ul>-->
<!--          <li> <b>JUL'23</b> - Our work on Learning-oriented Robot Design was accepted at IROS 2023 <a-->
<!--            href="https://learning-robot.github.io/">[project page]</a></li>-->
<!--          <li> <b>MAR'23</b> - Check out our latest work on Design a Learning Robot <a-->
<!--              href="https://learning-robot.github.io/">[project page]</a></li>-->
<!--          <li> <b>APR'22</b> - Human Motion Control of Quadrupedal Robots accepted at RSS <a-->
<!--              href="https://sites.google.com/view/humanconquad/">[project page]</a></li>-->
<!--          <li> <b>SEP'21</b> - Excited to be joining <a href="https://x.company">X - the moonshot factory</a> ( <a-->
<!--              href="https://everydayrobots.com">Everyday Robots</a> ) for PhD-->
<!--            Residency!</li>-->
<!--          <li> <b>SEP'21</b> - Check out our work on Learning Sidewalk Navigation <a-->
<!--              href="./navigation.html">[project page]</a></li>-->
<!--          &lt;!&ndash; <li> <b>MAY'21</b> - Awarded the fellowship by the Machine Learning Center at Georgia Tech. <a href="https://mlatgt.blog/2021/05/10/the-machine-learning-center-awards-inaugural-mlgt-fellows/">[link]</a> </li> &ndash;&gt;-->
<!--          &lt;!&ndash; <li> <b>FEB'21</b> Paper on Learning Human Search Behavior accepted at EUROGRAPHICS'2021! <a href="https://arxiv.org/pdf/2011.03618.pdf">[pdf]</a><a href="https://arxiv.org/abs/2011.03618">[arXiv]</a></li> &ndash;&gt;-->
<!--          &lt;!&ndash; <li> <b>DEC'20</b> Paper on Few-shot visual sensor meta-adaptation accepted at ICRA'2021! <a href="https://arxiv.org/pdf/2011.03609.pdf">[pdf]</a><a href="http://arxiv.org/abs/2011.03609">[arXiv]</a></li> &ndash;&gt;-->
<!--        </ul>-->


      </div>

    </div>
  </div>

  <!-- Companies
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
<!--  <div class="container">-->
<!--    <div class="div_line"></div><br>-->
<!--    <div class="row">-->
<!--      <div class="one column hide-on-small">&nbsp;</div>-->
<!--      <div class="five columns center">-->
<!--        <a href="https://www.gatech.edu/">-->
<!--          <img src="assets/icons/org/GeorgiaTechLogo.png" alt="Georgia Tech Logo" class="logo">-->
<!--        </a>-->
<!--        <p>-->
<!--          PhD in Computer Science<br>2023 - -->
<!--        </p>-->
<!--      </div>-->
<!--&lt;!&ndash;      <div class="five columns center">&ndash;&gt;-->
<!--&lt;!&ndash;        <div class="row">&ndash;&gt;-->
<!--&lt;!&ndash;          <a href="https://everydayrobots.com">&ndash;&gt;-->
<!--&lt;!&ndash;            <img src="assets/icons/org/EverydayRobotsLogo.gif" alt="Everyday Robots Logo" class="logo">&ndash;&gt;-->
<!--&lt;!&ndash;          </a>&ndash;&gt;-->
<!--&lt;!&ndash;          <a href="https://x.company">&ndash;&gt;-->
<!--&lt;!&ndash;            <img src="assets/icons/org/X the moonshot factory logo.png" alt="Google X Logo" class="logo">&ndash;&gt;-->
<!--&lt;!&ndash;          </a>&ndash;&gt;-->
<!--&lt;!&ndash;        </div>&ndash;&gt;-->
<!--&lt;!&ndash;        <p>&ndash;&gt;-->
<!--&lt;!&ndash;          AI Residency<br>2021 - 2022&ndash;&gt;-->
<!--&lt;!&ndash;        </p>&ndash;&gt;-->
<!--&lt;!&ndash;      </div>&ndash;&gt;-->
<!--    </div>-->
<!--  </div>-->
  

  <!-- Publications
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <div class="container">
    <br>
    <div class="div_line"></div><br>
    <h5><u>Publications</u></h5>

    <!-- PUBLICATION ENTRY –––––––––––––––––––––––––––––––––––––––––––––––––– -->
    <div class="row video-row">
      <!-- MEDIA SECTION –––––––––––––––––––––––––––––––––––––––––––––––––– -->
      <div class="four columns">
        <div class="video-container">
          <img src="assets/img/Memory Management.png">
        </div>
      </div>
      <div class="eight columns text-column">
        <!-- TITLE –––––––––––––––––––––––––––––––––––––––––––––––––– -->
        <div class="project_title">Effortless Integration of Memory Management into Open-Domain Conversation Systems</div>
        <!-- AUTHORS + VENUE –––––––––––––––––––––––––––––––––––––––––––––––––– -->
        <br><em>Eunbi Choi, Kyoung-Woon On, Gunsoo Han, Sungwoong Kim, Daniel Wontae Nam, Daejin Jo, <strong>Seungeun Rho</strong>, Taehwan Kwon, Minjoon Seo</em>
        <br><em><span class="venue">Arxiv</span></em>
        <!-- DESCRIPTION –––––––––––––––––––––––––––––––––––––––––––––––––– -->
        <p class="project_info">
          We propose an automating dataset creation for memory management. Our method 1) requires little cost for data construction, 2) does not affect performance in other tasks, and 3) reduces external memory. We show that our proposed model BlenderBot3-M^3, which is multi-task trained with memory management, outperforms BlenderBot3 with a relative 4% performance gain in terms of F1 score.</p>

        <!-- LINKS –––––––––––––––––––––––––––––––––––––––––––––––––– -->
        <a href="https://arxiv.org/abs/2305.13973">[Arxiv]</a>
      </div>
    </div>

    <!-- PUBLICATION ENTRY –––––––––––––––––––––––––––––––––––––––––––––––––– -->
    <div class="row video-row">
      <!-- MEDIA SECTION –––––––––––––––––––––––––––––––––––––––––––––––––– -->
      <div class="four columns">
        <div class="video-container">
          <img src="assets/img/LECO.png">
        </div>
      </div>
      <div class="eight columns text-column">
        <!-- TITLE –––––––––––––––––––––––––––––––––––––––––––––––––– -->
        <div class="project_title">LECO: Learnable Episodic Count for Task-Specific Intrinsic Reward</div>
        <!-- AUTHORS + VENUE –––––––––––––––––––––––––––––––––––––––––––––––––– -->
        <br><em>Daejin Jo, Sungwoong Kim, Daniel Wontae Nam, Taehwan Kwon, <strong>Seungeun Rho</strong>, Jongmin Kim, Donghoon Lee </em>
        <br><em><span class="venue">Neural Information Processing Systems (NeurIPS) 2022</span></em>
        <!-- DESCRIPTION –––––––––––––––––––––––––––––––––––––––––––––––––– -->
        <p class="project_info">
          We propose a learnable hash-based episodic count, which we name LECO, that efficiently performs as a task-specific intrinsic reward in hard exploration problems. In particular, the proposed intrinsic reward consists of the episodic novelty and the task-specific modulation where the former employs a vector quantized variational autoencoder to automatically obtain the discrete state codes for fast counting while the latter regulates the episodic novelty by learning a modulator to optimize the task-specific extrinsic reward.
        </p>

        <!-- LINKS –––––––––––––––––––––––––––––––––––––––––––––––––– -->
        <a href="https://proceedings.neurips.cc/paper_files/paper/2022/file/c43b2989b1ba055aa713a4abbe4a8b05-Paper-Conference.pdf">[pdf]</a>
      </div>
    </div>

    <div class="row video-row">
      <!-- MEDIA SECTION –––––––––––––––––––––––––––––––––––––––––––––––––– -->
      <div class="four columns">
        <div class="video-container">
          <img src="assets/img/bladeandsoul.jpg">
        </div>
      </div>
      <div class="eight columns text-column">
        <!-- TITLE –––––––––––––––––––––––––––––––––––––––––––––––––– -->
        <div class="project_title">Creating Pro-Level AI for a Real-Time Fighting Game using Deep Reinforcement Learning</div>
        <!-- AUTHORS + VENUE –––––––––––––––––––––––––––––––––––––––––––––––––– -->
        <br><em>Inseok Oh, <strong>Seungeun Rho</strong>, Sangbin Moon, Seongho Son, Hyoil Lee, Jinyun Chung</em>
        <br><em><span class="venue">AAAI 22' RL in Games Workshop</span></em>
        <!-- DESCRIPTION –––––––––––––––––––––––––––––––––––––––––––––––––– -->
        <p class="project_info">
          In simultaneous games, ensuring diversity during self-play is key to achieve optimal policy.
          We devised a novel self-play curriculum based on reward shaping to ensure agent diversity.
          Final agent trained with proposed curriculum, beat pro-player in 3D real-time fighting game.</p>
        <!-- LINKS –––––––––––––––––––––––––––––––––––––––––––––––––– -->
        <a href="https://arxiv.org/abs/1904.03821">[Arxiv]</a>
      </div>
    </div>



<!--    &lt;!&ndash; PUBLICATION ENTRY –––––––––––––––––––––––––––––––––––––––––––––––––– &ndash;&gt;-->
<!--    <div class="row video-row">-->
<!--      &lt;!&ndash; MEDIA SECTION –––––––––––––––––––––––––––––––––––––––––––––––––– &ndash;&gt;-->
<!--      <div class="four columns">-->
<!--        <div class="video-container">-->
<!--          <video class="no-controls-video" autoplay loop muted preload="auto" playsinline>-->
<!--            <source src="assets/videos/sensor_height_adaptation.mp4" type="video/mp4">-->
<!--          </video>-->
<!--        </div>-->
<!--      </div>-->
<!--      <div class="eight columns text-column">-->
<!--        &lt;!&ndash; TITLE –––––––––––––––––––––––––––––––––––––––––––––––––– &ndash;&gt;-->
<!--        <div class="project_title">A Few Shot Adaptation of Visual Navigation Skills to New Observations using-->
<!--          Meta-Learning</div>-->
<!--        &lt;!&ndash; AUTHORS + VENUE –––––––––––––––––––––––––––––––––––––––––––––––––– &ndash;&gt;-->
<!--        <br><em>Qian Luo, <strong>Maks Sorokin</strong>, Sehoon Ha</em>-->
<!--        <br><em><span class="venue">The IEEE International Conference on Robotics and Automation (ICRA) 2021</span></em>-->
<!--        &lt;!&ndash; DESCRIPTION –––––––––––––––––––––––––––––––––––––––––––––––––– &ndash;&gt;-->
<!--        <p class="project_info">-->
<!--          We show how vision-based navigation agents can be trained to adapt to new sensor configurations with only-->
<!--          three shots of experience.-->
<!--          Rapid adaptation is achieved by introducing a bottleneck between perception and control networks, and through-->
<!--          the perception component's meta-adaptation.-->
<!--        </p>-->
<!--        &lt;!&ndash; LINKS –––––––––––––––––––––––––––––––––––––––––––––––––– &ndash;&gt;-->
<!--        <a href="https://arxiv.org/pdf/2011.03609.pdf">[pdf]</a>-->
<!--        <a href="http://arxiv.org/abs/2011.03609">[arXiv]</a>-->
<!--      </div>-->
<!--    </div>-->

  </div>

  <!-- Projects
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <div class="container">
    <br>
    <div class="div_line"></div><br>
    <h5><u>Projects</u></h5>

    <!-- PROJECT ENTRY ###
    –––––––––––––––––––––––––––––––––––––––––––––––––– -->
    <div class="row video-row">
      <!-- MEDIA SECTION
      –––––––––––––––––––––––––––––––––––––––––––––––––– -->
      <div class="four columns">
        <div class="video-container">
          <img src="assets/img/iglu.gif">
        </div>
      </div>
      <div class="eight columns">
        <!-- TITLE
        –––––––––––––––––––––––––––––––––––––––––––––––––– -->
        <div class="project_title">NeurIPS 22' IGLU Challenge - RL Track</div>
        <br><em><span class="venue">2022</span></em>
        <!-- DESCRIPTION
        –––––––––––––––––––––––––––––––––––––––––––––––––– -->
        <p class="project_info">
          Both 1st place winner & research prize winner,
          The task is about following natural language instructions to build a target structure without seeing what it should look like at the end.
          The RL agent observes the environment from a first-person point-of-view and is able to move around and place different colored blocks within a predefined building zone.

        </p>
        <!-- LINKS
        –––––––––––––––––––––––––––––––––––––––––––––––––– -->
        <a href="https://www.aicrowd.com/challenges/neurips-2022-iglu-challenge/problems/neurips-2022-iglu-challenge-rl-task/leaderboards">[project]</a>

      </div>
    </div>



    <!-- PUBLICATION ENTRY –––––––––––––––––––––––––––––––––––––––––––––––––– -->
    <div class="row video-row">
      <!-- MEDIA SECTION –––––––––––––––––––––––––––––––––––––––––––––––––– -->
      <div class="four columns">
        <div class="video-container">
          <img src="assets/img/Manchester City.png">
        </div>
      </div>
      <div class="eight columns text-column">
        <!-- TITLE –––––––––––––––––––––––––––––––––––––––––––––––––– -->
        <div class="project_title">Google Research & Manchester City F.C., RL Competition</div>
        <br><em><span class="venue">2021</span></em>
        <!-- DESCRIPTION –––––––––––––––––––––––––––––––––––––––––––––––––– -->
        <p class="project_info">
          Football AI RL Competition. Achieved gold medal and ranked in 6th out of 1,138 teams.
        </p>

        <!-- LINKS –––––––––––––––––––––––––––––––––––––––––––––––––– -->
        <a href="https://www.kaggle.com/c/google-football">[project]</a>
        <a href="https://github.com/seungeunrho/football-paris">[github]</a>
        <a href="https://www.kaggle.com/c/google-football/discussion/201376">[approach]</a>



      </div>
    </div>

  </div>

  <br>
  <br>

  <!-- Teaching –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <div class="container">
    <div class="div_line"></div><br><br>
    <div class="row profile-row">
      <div class="one columns hide-on-small">&nbsp;</div>
      <div class="nine columns ">

        <h5><u>Teaching Experience</u></h5>
        <br>CS4496 - Computer Animation class by
        <a href="https://www.cc.gatech.edu/~sha9/"> Dr. Sehoon Ha</a>
        <br><br>
        <ul>
          <li><strong>SPRING 2023</strong>: Teaching Assistant </li>
        </ul>
        <br>
<!--        <h5><u>Scholarly Activities</u></h5>-->
<!--        <ul>-->
<!--          <li><strong>IROS 2023</strong> - Session co-chair Mechanism Design </li>-->
<!--          <li><strong>RA-L 2023</strong> - Reviewer at IEEE Robotics and Automation Letters </li>-->
<!--          <li><strong>RSS 2023</strong> - Reviewer at Proceedings of Robotics: Science and Systems </li>-->
<!--          <li><strong>RA-L 2022</strong> - Reviewer at IEEE Robotics and Automation Letters</li>-->
<!--          <li><strong>ICRA 2021</strong> - Reviewer at IEEE International Conference on Robotics and Automation</li>-->
<!--        </ul>-->
      </div>
    </div>
  </div>


  <!-- End Document
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <!-- attempt hiding from spambots :p - snippet credits Andrej Karpathy - karpathy.ai source code -->
  <script type="text/javascript">
    var e_is_shown = false;
    document.getElementById('iemail').addEventListener("click", function () {
      let demail = document.getElementById('demail');
      demail.innerHTML = 's' + 'eungeun' + ' _a' + 't_ ' + 'gatech' + '.' + 'e' + 'du';
      demail.style.opacity = e_is_shown ? 0 : 1;
      e_is_shown = !e_is_shown;
    })
  </script>


  <!-- ### FOOTER ### -->

<!--  <br>-->
<!--  <br>-->

<!--  <br>-->
<!--  <br>-->
<!--  <div class="div_line"></div><br>-->

<!--  <p style="color:gray; text-align:center; font-size: small;">-->
<!--    <h7 style="text-decoration: none;">consider checking out: </h7><br><br>-->
<!--    <a href="https://www.givewell.org/"><img src="assets/icons/gw.jpg" style="width:100px;"></a>-->
<!--    <a href="https://www.givingwhatwecan.org/"><img src="assets/icons/gwwc.png" style="width:100px;"></a>-->
<!--    <a href="https://www.effectivealtruism.org/"><img src="assets/icons/ea.png" style="width:80px; margin:10px"></a>-->

<!--  </p>-->


<!--  <div class="div_line"></div><br>-->

<!--  <p style="color:gray; text-align:center; font-size: small;">-->
<!--    2023© Seungeun Rho<br>-->
<!--    built using <a href="http://getskeleton.com/">Skeleton</a>,-->
<!--    icon credits <a href="https://www.flaticon.com/"> flaticon</a>,-->
<!--    hosted by <a href="https://pages.github.com/"> GitHub Pages</a>❤️-->
<!--    <br>-->
<!--    <br>-->
<!--    feel free to copy: <a href="https://github.com/initmaks/initmaks.github.io">this page</a>-->
<!--  </p>-->

</body>

</html>